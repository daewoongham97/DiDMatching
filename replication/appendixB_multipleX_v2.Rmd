---
title: "Simulation to assess varying coefficients and guideline"
output:
  pdf_document: default
  html_document: default
editor_options:
  chunk_output_type: console
---


```{r setup, include=FALSE}
library( tidyverse )
library(ggplot2); library(latex2exp); library(gridExtra); library(ggpubr)

theme_set( theme_minimal() )
knitr::opts_chunk$set(fig.width = 6,
                      fig.height = 3,
                      out.width = "80%", 
                      fig.align = "center",
                      warning = FALSE )
options(list(dplyr.summarise.inform = FALSE))
theme_set( theme_classic() )


source( here::here( "replication/sim_functions.R" ) )
source( here::here( "oracle_bias_calculators.R" ) )
source( here::here( "DiD_matching_func.R" ) )

```


This runs a series of small simulations where we examine varying beta coefficients over time. In these simulations, we generate data and estimate the guidelines based on that data, and then compare these estimated recommendations to the oracle truth (using our general theorem) to see how our guideline works when it is technically misspecified. 

In particular, this document produces Figure 4 and Table 2 in Appendix B. 



# Run simulation across range of sigma_pre

Our initial simulation has varying coefficients for both $X$ and $Z$, along with $\theta$. The misspecification gives a reduced recommendation to match as shown on the figure to the right.

```{r}
# Number of simulation replicates per scenario
K = 50 #1000

sigma_pre_tests = seq( 0.3, 1.5, by=0.10 ) 

names(sigma_pre_tests) = sigma_pre_tests 
sim_res <- map_df( sigma_pre_tests, 
                   ~ run_scenario( sigma_pre = .,
                                   beta_theta_0 = c( 0.5, 1.0 ),
                                   beta_theta_1 = 1.5,
                                   beta_x_0 = c( 0.6, 1.1),
                                   beta_x_1 = 1.3,
                                   beta_z_0 = c( 0.3, 0.7 ),
                                   beta_z_1 = 1.0,
                                   cor_XZ = 0.5,
                                   K = K ),
                   .id = "sigma_pre" ) %>%
    mutate( sigma_pre = as.numeric(sigma_pre) )

saveRDS(sim_res, file = "results/plot_df.rds")
```

Our table shows, for different residual variation, the proportion of the trials that say "match!", the average estimated reduction in bias, the standard deviation of the estimates across simulation (which is the true SE), and whether the oracle says to match and how much bias would be reduced.  The last column is the $R^2$ for a regression of outcome onto the two observed covariates to get a sense of how much variation is explained by what we can match on.

```{r, echo=FALSE}
sim_res %>% 
    dplyr::select( sigma_pre, per_match, a_tau_xy, SE_tau_xy, match_XY, reduce_XY, R2 ) %>%
    knitr::kable( digits = 3 )
```

The plot is as discussed in the appendix:

```{r, echo=FALSE}
plt <- make_result_plot( sim_res )
plt
```


\newpage

# Independent covariates

This is our initial simulation, except the covariates are no independent.  The independence does not help us?

```{r}
sim_resB <- map_df( sigma_pre_tests, 
                   ~ run_scenario( sigma_pre = .,
                                   beta_theta_0 = c( 0.5, 1.0 ),
                                   beta_theta_1 = 1.5,
                                   beta_x_0 = c( 0.6, 1.1),
                                   beta_x_1 = 1.3,
                                   beta_z_0 = c( 0.3, 0.7 ),
                                   beta_z_1 = 1.0,
                                   cor_XZ = 0.0,
                                   cor_Xtheta = c(0,0),
                                   K = K ),
                   .id = "sigma_pre" ) %>%
    mutate( sigma_pre = as.numeric(sigma_pre) )
```

```{r, echo=FALSE}
saveRDS(sim_resB, file = "results/plotB_df.rds")

plt <- make_result_plot( sim_resB )
plt
```


\newpage

# Alternate scenario: correct specification

If we have parallel trends for all three covariates (two observed, one latent) then our guideline works as expected.

Also note that due to large sample size our match recommendation is very precisely estimated because our bias reduction is also very precisely estimated (see the SE column).

```{r}
sim_res2 <- map_df( sigma_pre_tests, 
                    ~ run_scenario( sigma_pre = .,
                                    K = K,
                                    beta_theta_0 = c( 0.75, 0.75 ),
                                    beta_theta_1 = 1.5,
                                    beta_x_0 = c( 0.85, 0.85),
                                    beta_x_1 = 1.3,
                                    beta_z_0 = c( 0.5, 0.5 ),
                                    beta_z_1 = 1.0,
                                    cor_XZ = 0.5 ),                                                        .id = "sigma_pre" ) %>%
    mutate( sigma_pre = as.numeric(sigma_pre) )
```

```{r, echo=FALSE}
saveRDS(sim_res2, file = "results/plot2_df.rds")
sim_res2 = readRDS( "results/plot2_df.rds" )

sim_res2 %>% 
    dplyr::select( sigma_pre, per_match, a_tau_xy, SE_tau_xy, match_XY, reduce_XY, R2 ) %>%
    knitr::kable( digits = 3 )


plt <- make_result_plot( sim_res2 )
plt
```


\newpage

# Alternate scenario: theta parallel, covariates not

Here we have X and Z correlated, but theta is parallel.

```{r}

sim_res3 <- map_df( sigma_pre_tests, 
                    ~ run_scenario( sigma_pre = .,
                                    K = K,
                                    beta_theta_0 = c( 0.75, 0.75 ),
                                    beta_theta_1 = 1.5,
                                    beta_x_0 = c( 0.6, 1.1),
                                    beta_x_1 = 1.3,
                                    beta_z_0 = c( 0.3, 0.7 ),
                                    beta_z_1 = 1.0,
                                    cor_XZ = 0.5 ),
                    .id = "sigma_pre" ) %>%
    mutate( sigma_pre = as.numeric(sigma_pre) )
```

```{r, echo=FALSE}
saveRDS(sim_res3, file = "results/plot3_df.rds")
sim_res3 = readRDS("results/plot3_df.rds" )
sim_res3 %>% 
    dplyr::select( sigma_pre, per_match, a_tau_xy, SE_tau_xy, match_XY, reduce_XY, R2 ) %>%
    knitr::kable( digits = 3 )


plt <- make_result_plot( sim_res3 )
plt
```


\newpage


# Alternate scenario: less predictive covariates, more time periods

If we make covariates less predictive, but have more pre-treatment time periods? (We have also increased variation in theta to cause more trouble.)

```{r}

sigmas_larger = sigma_pre_tests * 2
names(sigmas_larger) = sigmas_larger
sim_res3 <- map_df( sigmas_larger, 
                    ~ run_scenario( sigma_pre = .,
                                    beta_theta_0 = c( 0, 0.3, 0.7, 1.0 ),
                                    beta_theta_1 = 1.5,
                                    beta_x_0 = c( 0.6, 1.1, 1.1, 0.6 ),
                                    beta_x_1 = 1.3,
                                    beta_z_0 = c( 0.7, 0.7, 0.3, 0.3 ),
                                    beta_z_1 = 1.0,
                                    cor_XZ = 0.5,
                                    K = K ),
                    .id = "sigma_pre" ) %>%
    mutate( sigma_pre = as.numeric(sigma_pre) )
```

```{r, echo=FALSE}
saveRDS(sim_res3, file = "results/plot3_df.rds")

sim_res3 %>% 
    dplyr::select( sigma_pre, per_match, a_tau_xy, SE_tau_xy, match_XY, reduce_XY, R2 ) %>%
    knitr::kable( digits = 3 )


plt <- make_result_plot( sim_res3 )
plt
```




\newpage

# Alternate scenario: narrow theta assumption only

If all we get is parallel theta in the final two periods, but theta is not parallel before that?

```{r}

sim_res4 <- map_df( sigmas_larger, 
                    ~ run_scenario( sigma_pre = .,
                                    beta_theta_0 = c( -0.5, 0.5, 1.0, 1.0 ),
                                    beta_theta_1 = 1.5,
                                    beta_x_0 = c( 0.6, 1.1, 1.1, 0.6 ),
                                    beta_x_1 = 1.3,
                                    beta_z_0 = c( 0.7, 0.7, 0.3, 0.3 ),
                                    beta_z_1 = 1.0,
                                    cor_XZ = 0.5,
                                    K = K ),
                    .id = "sigma_pre" ) %>%
    mutate( sigma_pre = as.numeric(sigma_pre) )
```

```{r, echo=FALSE}
saveRDS(sim_res4, file = "results/plot4_df.rds")

plt <- make_result_plot( sim_res4 )
plt
```


\newpage

# Alternate scenario: small sample size

If we reduce sample size, estimation error should flatten our curve.  It seems like estimation error is very small, which is surprising given all the residualization?


```{r}

sim_res5 <- map_df( sigma_pre_tests, 
                    ~ run_scenario( sigma_pre = .,
                                   beta_theta_0 = c( 0.5, 1.0 ),
                                   beta_theta_1 = 1.5,
                                   beta_x_0 = c( 0.6, 1.1),
                                   beta_x_1 = 1.3,
                                   beta_z_0 = c( 0.3, 0.7 ),
                                   beta_z_1 = 1.0,
                                   cor_XZ = 0.5,
                                    N = 3000 ),
                    .id = "sigma_pre" ) %>%
    mutate( sigma_pre = as.numeric(sigma_pre) )
```

```{r, echo=FALSE}
saveRDS(sim_res5, file = "results/plot5_df.rds" )
sim_res5 = readRDS( "results/plot5_df.rds" )
sim_res5 %>% 
    dplyr::select( sigma_pre, per_match, a_tau_xy, SE_tau_xy, match_XY, reduce_XY, R2 ) %>%
    knitr::kable( digits = 3 )

plt <- make_result_plot( sim_res5 )
plt
```


\newpage

# Alternate scenario: theta independent

Here we have our theta stable in the final two time periods, and no correlation between any of our three. covariates.

```{r}

sim_res6 <- map_df( sigmas_larger, 
                    ~ run_scenario( sigma_pre = .,
                                    beta_theta_0 = c( -0.5, 0.5, 1.0, 1.0 ),
                                    beta_theta_1 = 1.5,
                                    beta_x_0 = c( 0.6, 1.1, 1.1, 0.6 ),
                                    beta_x_1 = 1.3,
                                    beta_z_0 = c( 0.7, 0.7, 0.3, 0.3 ),
                                    beta_z_1 = 1.0,
                                    cor_XZ = 0,
                                    cor_Xtheta = c( 0, 0 ),
                                    K = K ),
                    .id = "sigma_pre" ) %>%
    mutate( sigma_pre = as.numeric(sigma_pre) )
```

```{r, echo=FALSE}
saveRDS(sim_res6, file = "results/plot6_df.rds")

sim_res6 %>% 
    dplyr::select( sigma_pre, per_match, a_tau_xy, SE_tau_xy, match_XY, reduce_XY, R2 ) %>%
    knitr::kable( digits = 3 )

plt <- make_result_plot( sim_res6 )
plt
```

